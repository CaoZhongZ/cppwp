<!DOCTYPE html><html lang='en'><head><title>[algorithms.parallel.exec]</title><meta charset='UTF-8'/><link rel='stylesheet' type='text/css' href='14882.css'/><link rel='icon' href='icon.png'/></head><body><div class='wrapper'><h1 ><a class='secnum' style='min-width:73pt'>28</a> Algorithms library <a class='abbr_ref' href='./#algorithms'>[algorithms]</a></h1><h2 ><a class='secnum' style='min-width:88pt'>28.4</a> Parallel algorithms <a class='abbr_ref' href='algorithms.parallel#exec'>[algorithms.parallel]</a></h2><h3 ><a class='secnum' style='min-width:103pt'>28.4.3</a> Effect of execution policies on algorithm execution <a class='abbr_ref'>[algorithms.parallel.exec]</a></h3><div class='para' id='1'><div class='marginalizedparent'><a class='marginalized' href='#1'>1</a></div><div class='sourceLinkParent'><a class='sourceLink' href='https://github.com/cplusplus/draft/tree/ae6271c88727c3fabe7dd8258f8687b369d83d6d/source/algorithms.tex#L1291'>#</a></div><p >Parallel algorithms have template parameters
named <a href='execpol'><span class='texttt'>ExecutionPolicy</span></a>
which describe the manner in which the execution of these algorithms may be
parallelized and the manner in which they apply the element access functions.</p></div><div class='para' id='2'><div class='marginalizedparent'><a class='marginalized' href='#2'>2</a></div><div class='sourceLinkParent'><a class='sourceLink' href='https://github.com/cplusplus/draft/tree/ae6271c88727c3fabe7dd8258f8687b369d83d6d/source/algorithms.tex#L1297'>#</a></div><p >Unless otherwise stated, implementations may make arbitrary copies of elements
(with type <span class='texttt'>T</span>) from sequences where <span class='texttt'>is_&shy;trivially_&shy;copy_&shy;constructible_&shy;v&lt;T&gt;</span>
and <span class='texttt'>is_&shy;trivially_&shy;destructible_&shy;v&lt;T&gt;</span> are <span class='texttt'>true</span>.
[<span style='white-space:nowrap'>&thinsp;</span><span class='textit'>Note:</span> 
This implies that user-supplied function objects should not rely on object
identity of arguments for such input sequences. Users for whom the object
identity of the arguments to these function objects is important should
consider using a wrapping iterator that returns a non-copied implementation
object such as <span class='texttt'>reference_&shy;wrapper&lt;T&gt;</span> (<a href='refwrap'>[refwrap]</a>) or some equivalent
solution.
<span class='textit'><span style='white-space:nowrap'>&thinsp;</span>—<span style='white-space:nowrap'>&thinsp;</span>end note</span><span style='white-space:nowrap'>&thinsp;</span>] </p></div><div class='para' id='3'><div class='marginalizedparent'><a class='marginalized' href='#3'>3</a></div><div class='sourceLinkParent'><a class='sourceLink' href='https://github.com/cplusplus/draft/tree/ae6271c88727c3fabe7dd8258f8687b369d83d6d/source/algorithms.tex#L1310'>#</a></div><p >The invocations of element access functions in parallel algorithms invoked with
an execution policy object of type <span class='texttt'>execution&#x200b;::&#x200b;sequenced_&shy;policy</span> all occur
in the calling thread of execution.
[<span style='white-space:nowrap'>&thinsp;</span><span class='textit'>Note:</span> 
The invocations are not interleaved; see <a href='intro.execution'>[intro.execution]</a>.
<span class='textit'><span style='white-space:nowrap'>&thinsp;</span>—<span style='white-space:nowrap'>&thinsp;</span>end note</span><span style='white-space:nowrap'>&thinsp;</span>] </p></div><div class='para' id='4'><div class='marginalizedparent'><a class='marginalized' href='#4'>4</a></div><div class='sourceLinkParent'><a class='sourceLink' href='https://github.com/cplusplus/draft/tree/ae6271c88727c3fabe7dd8258f8687b369d83d6d/source/algorithms.tex#L1318'>#</a></div><p >The invocations of element access functions in parallel algorithms invoked with
an execution policy object of type <span class='texttt'>execution&#x200b;::&#x200b;parallel_&shy;policy</span> are
permitted to execute in either the invoking thread of execution or in a
thread of execution implicitly
created by the library to support parallel algorithm execution.
If the threads of execution created by <a href='thread.thread.class'><span class='texttt'>thread</span></a> provide
<a href='intro.progress#def:concurrent_forward_progress_guarantees'>concurrent forward progress guarantees</a>, then a thread of execution
implicitly created by the library will provide parallel forward progress guarantees;
otherwise, the provided forward progress guarantee is
<span class='indexparent'><a class='index' id=':forward_progress_guarantees_for_implicit_threads_of_parallel_algorithms_(if_not_defined_for_thread)'></a></span>implementation-defined.
Any such
invocations executing in the same thread of execution are indeterminately sequenced with
respect to each other.
[<span style='white-space:nowrap'>&thinsp;</span><span class='textit'>Note:</span> 
It is the caller's responsibility to ensure that the
invocation does not introduce data races or deadlocks.
<span class='textit'><span style='white-space:nowrap'>&thinsp;</span>—<span style='white-space:nowrap'>&thinsp;</span>end note</span><span style='white-space:nowrap'>&thinsp;</span>] 
[<span style='white-space:nowrap'>&thinsp;</span><span class='textit'>Example:</span> 
</p><pre class='codeblock'>
int a[] = {0,1};
std::vector&lt;int&gt; v;
std::for_each(std::execution::par, std::begin(a), std::end(a), [&amp;](int i) {
  v.push_back(i*2+1); <span class='comment'>// incorrect: data race
</span>});</pre><p >The program above has a data race because of the unsynchronized access to the
container <span class='texttt'>v</span>.
<span class='textit'><span style='white-space:nowrap'>&thinsp;</span>—<span style='white-space:nowrap'>&thinsp;</span>end example</span><span style='white-space:nowrap'>&thinsp;</span>] 
[<span style='white-space:nowrap'>&thinsp;</span><span class='textit'>Example:</span> 
</p><pre class='codeblock'>
std::atomic&lt;int&gt; x{0};
int a[] = {1,2};
std::for_each(std::execution::par, std::begin(a), std::end(a), [&amp;](int) {
  x.fetch_add(1, std::memory_order_relaxed);
  <span class='comment'>// spin wait for another iteration to change the value of <span class='tcode_in_codeblock'>x</span>
</span>  while (x.load(std::memory_order_relaxed) == 1) { } <span class='comment'>// incorrect: assumes execution order
</span>});</pre><p >The above example depends on the order of execution of the iterations, and
will not terminate if both iterations are executed sequentially on the same
thread of execution.
<span class='textit'><span style='white-space:nowrap'>&thinsp;</span>—<span style='white-space:nowrap'>&thinsp;</span>end example</span><span style='white-space:nowrap'>&thinsp;</span>] 
[<span style='white-space:nowrap'>&thinsp;</span><span class='textit'>Example:</span> 
</p><pre class='codeblock'>
int x = 0;
std::mutex m;
int a[] = {1,2};
std::for_each(std::execution::par, std::begin(a), std::end(a), [&amp;](int) {
  std::lock_guard&lt;mutex&gt; guard(m);
  ++x;
});</pre><p >The above example synchronizes access to object <span class='texttt'>x</span> ensuring that it is
incremented correctly.
<span class='textit'><span style='white-space:nowrap'>&thinsp;</span>—<span style='white-space:nowrap'>&thinsp;</span>end example</span><span style='white-space:nowrap'>&thinsp;</span>] </p></div><div class='para' id='5'><div class='marginalizedparent'><a class='marginalized' href='#5'>5</a></div><div class='sourceLinkParent'><a class='sourceLink' href='https://github.com/cplusplus/draft/tree/ae6271c88727c3fabe7dd8258f8687b369d83d6d/source/algorithms.tex#L1375'>#</a></div><p >The invocations of element access functions in parallel algorithms invoked with
an execution policy of type <span class='texttt'>execution&#x200b;::&#x200b;parallel_&shy;unsequenced_&shy;policy</span> are
permitted to execute in an unordered fashion in unspecified threads of execution, and
unsequenced with respect to one another within each thread of execution.
These threads of execution are either the invoking thread of execution or threads of
execution implicitly created by the library; the latter will provide weakly parallel
forward progress guarantees.
[<span style='white-space:nowrap'>&thinsp;</span><span class='textit'>Note:</span> 
This means that multiple function object invocations may be interleaved on a
single thread of execution, which overrides the usual guarantee from <a href='intro.execution'>[intro.execution]</a>
that function executions do not interleave with one another.
<span class='textit'><span style='white-space:nowrap'>&thinsp;</span>—<span style='white-space:nowrap'>&thinsp;</span>end note</span><span style='white-space:nowrap'>&thinsp;</span>] 
Since <span class='texttt'>execution&#x200b;::&#x200b;parallel_&shy;unsequenced_&shy;policy</span> allows the execution of element
access functions to be interleaved on a single thread of execution, blocking synchronization,
including the use of mutexes, risks deadlock. Thus, the synchronization with
<span class='texttt'>execution&#x200b;::&#x200b;parallel_&shy;unsequenced_&shy;policy</span> is restricted as
follows:
A standard library function is <a class='hidden_link' href='#def:vectorization-unsafe' id='def:vectorization-unsafe'><i >vectorization-unsafe</i></a> if it is specified
to synchronize with another function invocation, or another function invocation
is specified to synchronize with it, and if it is not a memory allocation or
deallocation function. Vectorization-unsafe standard library functions may not
be invoked by user code called from <span class='texttt'>execution&#x200b;::&#x200b;parallel_&shy;unsequenced_&shy;policy</span>
algorithms.
[<span style='white-space:nowrap'>&thinsp;</span><span class='textit'>Note:</span> 
Implementations must ensure that internal synchronization inside standard
library functions does not prevent forward progress when those functions are
executed by threads of execution with weakly parallel forward progress guarantees.
<span class='textit'><span style='white-space:nowrap'>&thinsp;</span>—<span style='white-space:nowrap'>&thinsp;</span>end note</span><span style='white-space:nowrap'>&thinsp;</span>] 
[<span style='white-space:nowrap'>&thinsp;</span><span class='textit'>Example:</span> 
</p><pre class='codeblock'>
int x = 0;
std::mutex m;
int a[] = {1,2};
std::for_each(std::execution::par_unseq, std::begin(a), std::end(a), [&amp;](int) {
  std::lock_guard&lt;mutex&gt; guard(m); <span class='comment'>// incorrect: <span class='tcode_in_codeblock'>lock_&shy;guard</span> constructor calls <span class='tcode_in_codeblock'>m.lock()</span>
</span>  ++x;
});</pre><p >The above program may result in two consecutive calls to <span class='texttt'>m.lock()</span> on
the same thread of execution (which may deadlock), because the applications of the function
object are not guaranteed to run on different threads of execution.
<span class='textit'><span style='white-space:nowrap'>&thinsp;</span>—<span style='white-space:nowrap'>&thinsp;</span>end example</span><span style='white-space:nowrap'>&thinsp;</span>] 
[<span style='white-space:nowrap'>&thinsp;</span><span class='textit'>Note:</span> 
The semantics of the <span class='texttt'>execution&#x200b;::&#x200b;parallel_&shy;policy</span> or the
<span class='texttt'>execution&#x200b;::&#x200b;parallel_&shy;unsequenced_&shy;policy</span> invocation allow the implementation to
fall back to sequential execution if the system cannot parallelize an algorithm
invocation due to lack of resources.
<span class='textit'><span style='white-space:nowrap'>&thinsp;</span>—<span style='white-space:nowrap'>&thinsp;</span>end note</span><span style='white-space:nowrap'>&thinsp;</span>] </p></div><div class='para' id='6'><div class='marginalizedparent'><a class='marginalized' href='#6'>6</a></div><div class='sourceLinkParent'><a class='sourceLink' href='https://github.com/cplusplus/draft/tree/ae6271c88727c3fabe7dd8258f8687b369d83d6d/source/algorithms.tex#L1425'>#</a></div><p >If an invocation of a parallel algorithm uses threads of execution implicitly
created by the library, then the invoking thread of execution will either</p><ul class='itemize'><li id='6.1'><div class='marginalizedparent' style='left:-7em'><a class='marginalized' href='#6.1'>(6.1)</a></div><p >temporarily block with forward progress guarantee delegation (<a href='intro.progress'>[intro.progress]</a>)
      on the completion of these library-managed threads of execution, or
</p></li><li id='6.2'><div class='marginalizedparent' style='left:-7em'><a class='marginalized' href='#6.2'>(6.2)</a></div><p >eventually execute an element access function;
</p></li></ul><p >the thread of execution will continue to do so until the algorithm is finished.
[<span style='white-space:nowrap'>&thinsp;</span><span class='textit'>Note:</span> 
In blocking with forward progress guarantee delegation in this context,
a thread of execution created by the library is considered to have
finished execution as soon as it has finished the execution of the
particular element access function that the invoking thread of execution
logically depends on.
<span class='textit'><span style='white-space:nowrap'>&thinsp;</span>—<span style='white-space:nowrap'>&thinsp;</span>end note</span><span style='white-space:nowrap'>&thinsp;</span>] </p></div><div class='para' id='7'><div class='marginalizedparent'><a class='marginalized' href='#7'>7</a></div><div class='sourceLinkParent'><a class='sourceLink' href='https://github.com/cplusplus/draft/tree/ae6271c88727c3fabe7dd8258f8687b369d83d6d/source/algorithms.tex#L1444'>#</a></div><p >The semantics of parallel algorithms invoked with an execution policy object of
<span class='indexparent'><a class='index' id=':additional_execution_policies_supported_by_parallel_algorithms'></a></span>implementation-defined type are
<span class='indexparent'><a class='index' id=':semantics_of_parallel_algorithms_invoked_with_implementation-defined_execution_policies'></a></span>implementation-defined.</p></div></div></body></html>