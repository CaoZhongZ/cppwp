<!DOCTYPE html><html lang='en'><head><title>[intro.multithread]</title><meta charset='UTF-8'/><link rel='stylesheet' type='text/css' href='14882.css'/></head><body><div class='wrapper'><h1 ><a class='secnum' style='min-width:73pt'>1</a> General <a class='abbr_ref' href='./#intro'>[intro]</a></h1><div id='intro.multithread'><h2 ><a class='secnum' style='min-width:88pt'>1.10</a> Multi-threaded executions and data races <a class='abbr_ref'>[intro.multithread]</a></h2><div class='para' id='1'><div class='marginalizedparent'><a class='marginalized' href='#1'>1</a></div><p ><span class='indexparent'><a class='index' id='threads,multiple'></a></span><span class='indexparent'><a class='index' id='operation,atomic'></a></span>A <a id='thread_of_execution'><i>thread of execution</i></a> (also known as a <a id='thread'><i>thread</i></a>) is a single flow of
control within a program, including the initial invocation of a specific
top-level function, and recursively including every function invocation
subsequently executed by the thread. [&nbsp;<i>Note:</i><span class='space'></span> When one thread creates another,
the initial call to the top-level function of the new thread is executed by the
new thread, not by the creating thread. <i>&nbsp;—&nbsp;end note</i>&nbsp;] Every thread in a program can
potentially access every object and function in a program.<a class='footnotenum' href='#footnote-10'>10</a> Under a hosted
implementation, a C++ program can have more than one thread running
concurrently. The execution of each thread proceeds as defined by the remainder
of this standard. The execution of the entire program consists of an execution
of all of its threads. [&nbsp;<i>Note:</i><span class='space'></span> Usually the execution can be viewed as an
interleaving of all its threads. However, some kinds of atomic operations, for
example, allow executions inconsistent with a simple interleaving, as described
below. <i>&nbsp;—&nbsp;end note</i>&nbsp;] Under a freestanding implementation, it is <span class='indexparent'><a class='index' id='number_of_threads_in_a_program_under_a_freestanding_implementation'></a></span>implementation-defined whether a program can
have more than one thread of execution.</p></div><div class='para' id='2'><div class='marginalizedparent'><a class='marginalized' href='#2'>2</a></div><p >A signal handler that is executed as a result of a call to the <span class='texttt'>raise</span>
function belongs to the same thread of execution as the call to the
<span class='texttt'>raise</span> function. Otherwise it is unspecified which thread of execution
contains a signal handler invocation.</p></div><div class='footnote' id='footnote-10'><div class='footnoteNumberParent'><a class='marginalized' href='#footnote-10'>10)</a></div><p >An object
with automatic or thread storage duration (<a href='basic.stc'>[basic.stc]</a>) is associated with
one specific thread, and can be accessed by a different thread only indirectly
through a pointer or reference (<a href='basic.compound'>[basic.compound]</a>).</p></div><div id='intro.races'><h3 ><a class='secnum' href='#intro.races' style='min-width:103pt'>1.10.1</a> Data races <a class='abbr_ref' href='intro.races'>[intro.races]</a></h3><div class='para' id='intro.races-1'><div class='marginalizedparent'><a class='marginalized' href='#intro.races-1'>1</a></div><p >The value of an object visible to a thread <i>T</i> at a particular point is the
initial value of the object, a value assigned to the object by <i>T</i>, or a
value assigned to the object by another thread, according to the rules below.
[&nbsp;<i>Note:</i><span class='space'></span> In some cases, there may instead be undefined behavior. Much of this
section is motivated by the desire to support atomic operations with explicit
and detailed visibility constraints. However, it also implicitly supports a
simpler view for more restricted programs. <i>&nbsp;—&nbsp;end note</i>&nbsp;]</p></div><div class='para' id='intro.races-2'><div class='marginalizedparent'><a class='marginalized' href='#intro.races-2'>2</a></div><p >Two expression evaluations <a id='conflict'><i>conflict</i></a> if one of them modifies a memory
location (<a href='intro.memory'>[intro.memory]</a>) and the other one reads or modifies the same
memory location.</p></div><div class='para' id='intro.races-3'><div class='marginalizedparent'><a class='marginalized' href='#intro.races-3'>3</a></div><p >The library defines a number of atomic operations (Clause <a href='atomics'>[atomics]</a>) and
operations on mutexes (Clause <a href='thread'>[thread]</a>) that are specially identified as
synchronization operations. These operations play a special role in making
assignments in one thread visible to another. A synchronization operation on one
or more memory locations is either a consume operation, an acquire operation, a
release operation, or both an acquire and release operation. A synchronization
operation without an associated memory location is a fence and can be either an
acquire fence, a release fence, or both an acquire and release fence. In
addition, there are relaxed atomic operations, which are not synchronization
operations, and atomic read-modify-write operations, which have special
characteristics. [&nbsp;<i>Note:</i><span class='space'></span> For example, a call that acquires a mutex will
perform an acquire operation on the locations comprising the mutex.
Correspondingly, a call that releases the same mutex will perform a release
operation on those same locations. Informally, performing a release operation on
<i>A</i> forces prior
<span class='indexparent'><a class='index' id='side_effects'></a></span>side effects on other memory locations to become visible
to other threads that later perform a consume or an acquire operation on
<i>A</i>. “Relaxed” atomic operations are not synchronization operations even
though, like synchronization operations, they cannot contribute to data races.
<i>&nbsp;—&nbsp;end note</i>&nbsp;]</p></div><div class='para' id='intro.races-4'><div class='marginalizedparent'><a class='marginalized' href='#intro.races-4'>4</a></div><p >All modifications to a particular atomic object <i>M</i> occur in some
particular total order, called the <a id='modification_order'><i>modification order</i></a> of <i>M</i>. If
<i>A</i> and <i>B</i> are modifications of an atomic object <i>M</i> and
<i>A</i> happens before (as defined below) <i>B</i>, then <i>A</i> shall precede
<i>B</i> in the modification order of <i>M</i>, which is defined below.
[&nbsp;<i>Note:</i><span class='space'></span> This states that the modification orders must respect the “happens
before” relationship. <i>&nbsp;—&nbsp;end note</i>&nbsp;] [&nbsp;<i>Note:</i><span class='space'></span> There is a separate order for each
atomic object. There is no requirement that these can be combined into a single
total order for all objects. In general this will be impossible since different
threads may observe modifications to different objects in inconsistent orders.
<i>&nbsp;—&nbsp;end note</i>&nbsp;]</p></div><div class='para' id='intro.races-5'><div class='marginalizedparent'><a class='marginalized' href='#intro.races-5'>5</a></div><p >A <a id='release_sequence'><i>release sequence</i></a> headed by a release operation <i>A</i> on an atomic object
<i>M</i> is a maximal contiguous sub-sequence of
<span class='indexparent'><a class='index' id='side_effects'></a></span>side effects in the
modification order of <i>M</i>, where the first operation is <span class='texttt'>A</span>, and
every subsequent operation</p><ul ><li ><p >is performed by the same thread that performed <span class='texttt'>A</span>, or
</p></li><li ><p >is an atomic read-modify-write operation.
</p></li></ul></div><div class='para' id='intro.races-6'><div class='marginalizedparent'><a class='marginalized' href='#intro.races-6'>6</a></div><p >Certain library calls <a id='synchronize_with'><i>synchronize with</i></a> other library calls performed by
another thread. For example, an atomic store-release synchronizes with a
load-acquire that takes its value from the store (<a href='atomics.order'>[atomics.order]</a>).
[&nbsp;<i>Note:</i><span class='space'></span> Except in the specified cases, reading a later value does not
necessarily ensure visibility as described below. Such a requirement would
sometimes interfere with efficient implementation. <i>&nbsp;—&nbsp;end note</i>&nbsp;] [&nbsp;<i>Note:</i><span class='space'></span> The
specifications of the synchronization operations define when one reads the value
written by another. For atomic objects, the definition is clear. All operations
on a given mutex occur in a single total order. Each mutex acquisition “reads
the value written” by the last mutex release. <i>&nbsp;—&nbsp;end note</i>&nbsp;]</p></div><div class='para' id='intro.races-7'><div class='marginalizedparent'><a class='marginalized' href='#intro.races-7'>7</a></div><p >An evaluation <i>A</i> <a id='carries_a_dependency'><i>carries a dependency</i></a> to an evaluation <i>B</i> if</p><ul ><li ><p >the value of <i>A</i> is used as an operand of <i>B</i>, unless:
</p><ul ><li ><p ><i>B</i> is an invocation of any specialization of
<span class='texttt'>std::kill_dependency</span> (<a href='atomics.order'>[atomics.order]</a>), or</p></li><li ><p ><i>A</i> is the left operand of a built-in logical AND (<span class='texttt'>&amp;&amp;</span>,
see <a href='expr.log.and'>[expr.log.and]</a>) or logical OR (<span class='texttt'>||</span>, see <a href='expr.log.or'>[expr.log.or]</a>) 
operator, or</p></li><li ><p ><i>A</i> is the left operand of a conditional (<span class='texttt'>?:</span>, see <a href='expr.cond'>[expr.cond]</a>)
operator, or</p></li><li ><p ><i>A</i> is the left operand of the built-in comma (<span class='texttt'>,</span>)
operator (<a href='expr.comma'>[expr.comma]</a>); </p></li></ul><p >or</p></li><li ><p ><i>A</i> writes a scalar object or bit-field <i>M</i>, <i>B</i> reads the value
written by <i>A</i> from <i>M</i>, and <i>A</i> is sequenced before <i>B</i>, or</p></li><li ><p >for some evaluation <i>X</i>, <i>A</i> carries a dependency to <i>X</i>, and 
<i>X</i> carries a dependency to <i>B</i>.</p></li></ul><p >[&nbsp;<i>Note:</i><span class='space'></span> “Carries a dependency to” is a subset of “is sequenced before”,
and is similarly strictly intra-thread. <i>&nbsp;—&nbsp;end note</i>&nbsp;]</p></div><div class='para' id='intro.races-8'><div class='marginalizedparent'><a class='marginalized' href='#intro.races-8'>8</a></div><p >An evaluation <i>A</i> is <a id='dependency-ordered_before'><i>dependency-ordered before</i></a> an evaluation
<i>B</i> if
</p><ul ><li ><p ><i>A</i> performs a release operation on an atomic object <i>M</i>, and, in
another thread, <i>B</i> performs a consume operation on <i>M</i> and reads a
value written by any
<span class='indexparent'><a class='index' id='side_effects'></a></span>side effect in the release sequence headed by <i>A</i>, or</p></li><li ><p >for some evaluation <i>X</i>, <i>A</i> is dependency-ordered before <i>X</i> and
<i>X</i> carries a dependency to <i>B</i>.</p></li></ul><p >[&nbsp;<i>Note:</i><span class='space'></span> The relation “is dependency-ordered before” is analogous to
“synchronizes with”, but uses release/consume in place of release/acquire.
<i>&nbsp;—&nbsp;end note</i>&nbsp;]</p></div><div class='para' id='intro.races-9'><div class='marginalizedparent'><a class='marginalized' href='#intro.races-9'>9</a></div><p >An evaluation <i>A</i> <a id='inter-thread_happens_before'><i>inter-thread happens before</i></a> an evaluation <i>B</i>
if</p><ul ><li ><p ><i>A</i> synchronizes with <i>B</i>, or</p></li><li ><p ><i>A</i> is dependency-ordered before <i>B</i>, or</p></li><li ><p >for some evaluation <i>X</i></p><ul ><li ><p ><i>A</i> synchronizes with <i>X</i> and <i>X</i> is sequenced before <i>B</i>,
or</p></li><li ><p ><i>A</i> is sequenced before <i>X</i> and <i>X</i> inter-thread happens before
<i>B</i>, or</p></li><li ><p ><i>A</i> inter-thread happens before <i>X</i> and <i>X</i> inter-thread happens
before <i>B</i>.
</p></li></ul></li></ul><p >[&nbsp;<i>Note:</i><span class='space'></span> The “inter-thread happens before” relation describes arbitrary
concatenations of “sequenced before”, “synchronizes with” and
“dependency-ordered before” relationships, with two exceptions. The first
exception is that a concatenation is not permitted to end with
“dependency-ordered before” followed by “sequenced before”. The reason for
this limitation is that a consume operation participating in a
“dependency-ordered before” relationship provides ordering only with respect
to operations to which this consume operation actually carries a dependency. The
reason that this limitation applies only to the end of such a concatenation is
that any subsequent release operation will provide the required ordering for a
prior consume operation. The second exception is that a concatenation is not
permitted to consist entirely of “sequenced before”. The reasons for this
limitation are (1) to permit “inter-thread happens before” to be transitively
closed and (2) the “happens before” relation, defined below, provides for
relationships consisting entirely of “sequenced before”. <i>&nbsp;—&nbsp;end note</i>&nbsp;]</p></div><div class='para' id='intro.races-10'><div class='marginalizedparent'><a class='marginalized' href='#intro.races-10'>10</a></div><p >An evaluation <i>A</i> <a id='happens_before'><i>happens before</i></a> an evaluation <i>B</i>
(or, equivalently, <i>B</i> <a id='happens_after'><i>happens after</i></a> <i>A</i>) if:</p><ul ><li ><p ><i>A</i> is sequenced before <i>B</i>, or
</p></li><li ><p ><i>A</i> inter-thread happens before <i>B</i>.
</p></li></ul><p >The implementation shall ensure that no program execution demonstrates a cycle
in the “happens before” relation. [&nbsp;<i>Note:</i><span class='space'></span> This cycle would otherwise be
possible only through the use of consume operations. <i>&nbsp;—&nbsp;end note</i>&nbsp;]</p></div><div class='para' id='intro.races-11'><div class='marginalizedparent'><a class='marginalized' href='#intro.races-11'>11</a></div><p >A <a id='side_effects,visible'><i>visible side effect</i></a> <i>A</i> on a scalar object or bit-field <i>M</i>
with respect to a value computation <i>B</i> of <i>M</i> satisfies the
conditions:</p><ul ><li ><p ><i>A</i> happens before <i>B</i> and
</p></li><li ><p >there is no other
<span class='indexparent'><a class='index' id='side_effects'></a></span>side effect <i>X</i> to <i>M</i> such that <i>A</i>
happens before <i>X</i> and <i>X</i> happens before <i>B</i>.
</p></li></ul><p >The value of a non-atomic scalar object or bit-field <i>M</i>, as determined by
evaluation <i>B</i>, shall be the value stored by the
<span class='indexparent'><a class='index' id='side_effects,visible'></a></span>visible side effect
<i>A</i>. [&nbsp;<i>Note:</i><span class='space'></span> If there is ambiguity about which side effect to a
non-atomic object or bit-field is visible, then the behavior is either
unspecified or undefined. <i>&nbsp;—&nbsp;end note</i>&nbsp;] [&nbsp;<i>Note:</i><span class='space'></span> This states that operations on
ordinary objects are not visibly reordered. This is not actually detectable
without data races, but it is necessary to ensure that data races, as defined
below, and with suitable restrictions on the use of atomics, correspond to data
races in a simple interleaved (sequentially consistent) execution. <i>&nbsp;—&nbsp;end note</i>&nbsp;]</p></div><div class='para' id='intro.races-12'><div class='marginalizedparent'><a class='marginalized' href='#intro.races-12'>12</a></div><p >The value of an
atomic object <i>M</i>, as determined by evaluation <i>B</i>, shall be the value
stored by some
side effect <i>A</i> that modifies <i>M</i>, where <i>B</i> does not happen
before <i>A</i>.
[&nbsp;<i>Note:</i><span class='space'></span>
The set of such side effects is also restricted by the rest of the rules
described here, and in particular, by the coherence requirements below.
<i>&nbsp;—&nbsp;end note</i>&nbsp;]</p></div><div class='para' id='intro.races-13'><div class='marginalizedparent'><a class='marginalized' href='#intro.races-13'>13</a></div><p >If an operation <i>A</i> that modifies an atomic object <i>M</i> happens before
an operation <i>B</i> that modifies <i>M</i>, then <i>A</i> shall be earlier
than <i>B</i> in the modification order of <i>M</i>. [&nbsp;<i>Note:</i><span class='space'></span> This requirement
is known as write-write coherence. <i>&nbsp;—&nbsp;end note</i>&nbsp;]</p></div><div class='para' id='intro.races-14'><div class='marginalizedparent'><a class='marginalized' href='#intro.races-14'>14</a></div><p >If a
<span class='indexparent'><a class='index' id='value_computation'></a></span>value computation <i>A</i> of an atomic object <i>M</i> happens before a
value computation <i>B</i> of <i>M</i>, and <i>A</i> takes its value from a side
effect <i>X</i> on <i>M</i>, then the value computed by <i>B</i> shall either be
the value stored by <i>X</i> or the value stored by a
<span class='indexparent'><a class='index' id='side_effects'></a></span>side effect <i>Y</i> on
<i>M</i>, where <i>Y</i> follows <i>X</i> in the modification order of <i>M</i>.
[&nbsp;<i>Note:</i><span class='space'></span> This requirement is known as read-read coherence. <i>&nbsp;—&nbsp;end note</i>&nbsp;]</p></div><div class='para' id='intro.races-15'><div class='marginalizedparent'><a class='marginalized' href='#intro.races-15'>15</a></div><p >If a
<span class='indexparent'><a class='index' id='value_computation'></a></span>value computation <i>A</i> of an atomic object <i>M</i> happens before an
operation <i>B</i> that modifies <i>M</i>, then <i>A</i> shall take its value from a side
effect <i>X</i> on <i>M</i>, where <i>X</i> precedes <i>B</i> in the
modification order of <i>M</i>. [&nbsp;<i>Note:</i><span class='space'></span> This requirement is known as
read-write coherence. <i>&nbsp;—&nbsp;end note</i>&nbsp;]</p></div><div class='para' id='intro.races-16'><div class='marginalizedparent'><a class='marginalized' href='#intro.races-16'>16</a></div><p >If a
<span class='indexparent'><a class='index' id='side_effects'></a></span>side effect <i>X</i> on an atomic object <i>M</i> happens before a value
computation <i>B</i> of <i>M</i>, then the evaluation <i>B</i> shall take its
value from <i>X</i> or from a
<span class='indexparent'><a class='index' id='side_effects'></a></span>side effect <i>Y</i> that follows <i>X</i> in the
modification order of <i>M</i>. [&nbsp;<i>Note:</i><span class='space'></span> This requirement is known as
write-read coherence. <i>&nbsp;—&nbsp;end note</i>&nbsp;]</p></div><div class='para' id='intro.races-17'><div class='marginalizedparent'><a class='marginalized' href='#intro.races-17'>17</a></div><p >[&nbsp;<i>Note:</i><span class='space'></span> The four preceding coherence requirements effectively disallow
compiler reordering of atomic operations to a single object, even if both
operations are relaxed loads. This effectively makes the cache coherence
guarantee provided by most hardware available to C++ atomic operations.
<i>&nbsp;—&nbsp;end note</i>&nbsp;]</p></div><div class='para' id='intro.races-18'><div class='marginalizedparent'><a class='marginalized' href='#intro.races-18'>18</a></div><p >[&nbsp;<i>Note:</i><span class='space'></span> The value observed by a load of an atomic depends on the “happens
before” relation, which depends on the values observed by loads of atomics.
The intended reading is that there must exist an
association of atomic loads with modifications they observe that, together with
suitably chosen modification orders and the “happens before” relation derived
as described above, satisfy the resulting constraints as imposed here. <i>&nbsp;—&nbsp;end note</i>&nbsp;]</p></div><div class='para' id='intro.races-19'><div class='marginalizedparent'><a class='marginalized' href='#intro.races-19'>19</a></div><p ><span class='indexparent'><a class='index' id='potentially_concurrent'></a></span>Two actions are <i>potentially concurrent</i> if
</p><ul ><li ><p >they are performed by different threads, or
</p></li><li ><p >they are unsequenced, and at least one is performed by a signal handler.
</p></li></ul><p ><span class='indexparent'><a class='index' id='data_race'></a></span>The execution of a program contains a <a id='data_race'><i>data race</i></a> if it contains two
potentially concurrent conflicting actions, at least one of which is not atomic,
and neither happens before the other,
except for the special case for signal handlers described below.
Any such data race results in undefined
behavior. [&nbsp;<i>Note:</i><span class='space'></span> It can be shown that programs that correctly use mutexes
and <span class='texttt'>memory_order_seq_cst</span> operations to prevent all data races and use no
other synchronization operations behave as if the operations executed by their
constituent threads were simply interleaved, with each
<span class='indexparent'><a class='index' id='value_computation'></a></span>value computation of an
object being taken from the last
<span class='indexparent'><a class='index' id='side_effects'></a></span>side effect on that object in that
interleaving. This is normally referred to as “sequential consistency”.
However, this applies only to data-race-free programs, and data-race-free
programs cannot observe most program transformations that do not change
single-threaded program semantics. In fact, most single-threaded program
transformations continue to be allowed, since any program that behaves
differently as a result must perform an undefined operation. <i>&nbsp;—&nbsp;end note</i>&nbsp;]</p></div><div class='para' id='intro.races-20'><div class='marginalizedparent'><a class='marginalized' href='#intro.races-20'>20</a></div><p >Two accesses to the same object of type <span class='texttt'>volatile sig_atomic_t</span> do not
result in a data race if both occur in the same thread, even if one or more
occurs in a signal handler. For each signal handler invocation, evaluations
performed by the thread invoking a signal handler can be divided into two
groups <i>A</i> and <i>B</i>, such that no evaluations in
<i>B</i> happen before evaluations in <i>A</i>, and the
evaluations of such <span class='texttt'>volatile sig_atomic_t</span> objects take values as though
all evaluations in <i>A</i> happened before the execution of the signal
handler and the execution of the signal handler happened before all evaluations
in <i>B</i>.</p></div><div class='para' id='intro.races-21'><div class='marginalizedparent'><a class='marginalized' href='#intro.races-21'>21</a></div><p >[&nbsp;<i>Note:</i><span class='space'></span> Compiler transformations that introduce assignments to a potentially
shared memory location that would not be modified by the abstract machine are
generally precluded by this standard, since such an assignment might overwrite
another assignment by a different thread in cases in which an abstract machine
execution would not have encountered a data race. This includes implementations
of data member assignment that overwrite adjacent members in separate memory
locations. Reordering of atomic loads in cases in which the atomics in question
may alias is also generally precluded, since this may violate the coherence
rules. <i>&nbsp;—&nbsp;end note</i>&nbsp;]</p></div><div class='para' id='intro.races-22'><div class='marginalizedparent'><a class='marginalized' href='#intro.races-22'>22</a></div><p >[&nbsp;<i>Note:</i><span class='space'></span> Transformations that introduce a speculative read of a potentially
shared memory location may not preserve the semantics of the C++ program as
defined in this standard, since they potentially introduce a data race. However,
they are typically valid in the context of an optimizing compiler that targets a
specific machine with well-defined semantics for data races. They would be
invalid for a hypothetical machine that is not tolerant of races or provides
hardware race detection. <i>&nbsp;—&nbsp;end note</i>&nbsp;]</p></div></div><div id='intro.progress'><h3 ><a class='secnum' href='#intro.progress' style='min-width:103pt'>1.10.2</a> Forward progress <a class='abbr_ref' href='intro.progress'>[intro.progress]</a></h3><div class='para' id='intro.progress-1'><div class='marginalizedparent'><a class='marginalized' href='#intro.progress-1'>1</a></div><p >The implementation may assume that any thread will eventually do one of the 
following:</p><ul ><li ><p >terminate,</p></li><li ><p >make a call to a library I/O function,</p></li><li ><p >read or modify a volatile object, or</p></li><li ><p >perform a synchronization operation or an atomic operation.
</p></li></ul><p >[&nbsp;<i>Note:</i><span class='space'></span> This is intended to allow compiler transformations such as removal of
empty loops, even when termination cannot be proven. <i>&nbsp;—&nbsp;end note</i>&nbsp;]</p></div><div class='para' id='intro.progress-2'><div class='marginalizedparent'><a class='marginalized' href='#intro.progress-2'>2</a></div><p >Executions of atomic functions
that are either defined to be lock-free (<a href='atomics.flag'>[atomics.flag]</a>)
or indicated as lock-free (<a href='atomics.lockfree'>[atomics.lockfree]</a>)
are <a id='lock-free_execution'><i>lock-free executions</i></a>.</p><ul ><li ><p >If there is only one thread that is not blocked (<a href='defns.block'>[defns.block]</a>)
  in a standard library function,
  a lock-free execution in that thread shall complete.
  [&nbsp;<i>Note:</i><span class='space'></span>
    Concurrently executing threads
    may prevent progress of a lock-free execution.
    For example,
    this situation can occur
    with load-locked store-conditional implementations.
    This property is sometimes termed obstruction-free.
  <i>&nbsp;—&nbsp;end note</i>&nbsp;]
</p></li><li ><p >When one or more lock-free executions run concurrently,
  at least one should complete.
  [&nbsp;<i>Note:</i><span class='space'></span>
    It is difficult for some implementations
    to provide absolute guarantees to this effect,
    since repeated and particularly inopportune interference
    from other threads
    may prevent forward progress,
    e.g.,
    by repeatedly stealing a cache line
    for unrelated purposes
    between load-locked and store-conditional instructions.
    Implementations should ensure
    that such effects cannot indefinitely delay progress
    under expected operating conditions,
    and that such anomalies
    can therefore safely be ignored by programmers.
    Outside this International Standard,
    this property is sometimes termed lock-free.
  <i>&nbsp;—&nbsp;end note</i>&nbsp;]
</p></li></ul></div><div class='para' id='intro.progress-3'><div class='marginalizedparent'><a class='marginalized' href='#intro.progress-3'>3</a></div><p >During the execution of a thread of execution, each of the following is termed
an <a id='execution_step'><i>execution step</i></a>:</p><ul ><li ><p >termination of the thread of execution,
</p></li><li ><p >access to a volatile object, or
</p></li><li ><p >completion of a call to a library I/O function, a
      synchronization operation, or an atomic operation.
</p></li></ul></div><div class='para' id='intro.progress-4'><div class='marginalizedparent'><a class='marginalized' href='#intro.progress-4'>4</a></div><p >An invocation of a standard library function that blocks (<a href='defns.block'>[defns.block]</a>)
is considered to continuously execute execution steps while waiting for the
condition that it blocks on to be satisfied.
[&nbsp;<i>Example:</i><span class='space'></span>
A library I/O function that blocks until the I/O operation is complete can
be considered to continuously check whether the operation is complete. Each
such check might consist of one or more execution steps, for example using
observable behavior of the abstract machine.
<i>&nbsp;—&nbsp;end example</i>&nbsp;]</p></div><div class='para' id='intro.progress-5'><div class='marginalizedparent'><a class='marginalized' href='#intro.progress-5'>5</a></div><p >[&nbsp;<i>Note:</i><span class='space'></span>
Because of this and the preceding requirement regarding what threads of execution
have to perform eventually, it follows that no thread of execution can execute
forever without an execution step occurring.
<i>&nbsp;—&nbsp;end note</i>&nbsp;]</p></div><div class='para' id='intro.progress-6'><div class='marginalizedparent'><a class='marginalized' href='#intro.progress-6'>6</a></div><p >A thread of execution <a id='make_progress,thread'><i>makes progress</i></a>
when an execution step occurs or a
lock-free execution does not complete because there are other concurrent threads
that are not blocked in a standard library function (see above).</p></div><div class='para' id='intro.progress-7'><div class='marginalizedparent'><a class='marginalized' href='#intro.progress-7'>7</a></div><p ><span class='indexparent'><a class='index' id='forward_progress_guarantees,concurrent'></a></span>For a thread of execution providing <a id='concurrent_forward_progress_guarantees'><i>concurrent forward progress guarantees</i></a>,
the implementation ensures that the thread will eventually make progress for as
long as it has not terminated.
[&nbsp;<i>Note:</i><span class='space'></span>
This is required regardless of whether or not other threads of executions (if any)
have been or are making progress. To eventually fulfill this requirement means that
this will happen in an unspecified but finite amount of time.
<i>&nbsp;—&nbsp;end note</i>&nbsp;]</p></div><div class='para' id='intro.progress-8'><div class='marginalizedparent'><a class='marginalized' href='#intro.progress-8'>8</a></div><p >It is <span class='indexparent'><a class='index' id='whether_the_thread_that_executes_main_and_the_threads_created_by_std::thread_provide_concurrent_forward_progress_guarantees'></a></span>implementation-defined whether the
implementation-created thread of execution that executes
<span class='texttt'>main</span> (<a href='basic.start.main'>[basic.start.main]</a>) and the threads of execution created by
<span class='texttt'>std::thread</span> (<a href='thread.thread.class'>[thread.thread.class]</a>) provide concurrent forward progress
guarantees.
[&nbsp;<i>Note:</i><span class='space'></span>
General-purpose implementations are encouraged to provide these guarantees.
<i>&nbsp;—&nbsp;end note</i>&nbsp;]</p></div><div class='para' id='intro.progress-9'><div class='marginalizedparent'><a class='marginalized' href='#intro.progress-9'>9</a></div><p ><span class='indexparent'><a class='index' id='forward_progress_guarantees,parallel'></a></span>For a thread of execution providing <a id='parallel_forward_progress_guarantees'><i>parallel forward progress guarantees</i></a>,
the implementation is not required to ensure that the thread will eventually make
progress if it has not yet executed any execution step; once this thread has
executed a step, it provides concurrent forward progress guarantees.</p></div><div class='para' id='intro.progress-10'><div class='marginalizedparent'><a class='marginalized' href='#intro.progress-10'>10</a></div><p >[&nbsp;<i>Note:</i><span class='space'></span>
This does not specify a requirement for when to start this thread of execution,
which will typically be specified by the entity that creates this thread of
execution. For example, a thread of execution that provides concurrent forward
progress guarantees and executes tasks from a set of tasks in an arbitrary order,
one after the other, satisfies the requirements of parallel forward progress for
these tasks.
<i>&nbsp;—&nbsp;end note</i>&nbsp;]</p></div><div class='para' id='intro.progress-11'><div class='marginalizedparent'><a class='marginalized' href='#intro.progress-11'>11</a></div><p ><span class='indexparent'><a class='index' id='forward_progress_guarantees,weakly_parallel'></a></span>For a thread of execution providing <a id='weakly_parallel_forward_progress_guarantees'><i>weakly parallel forward progress
guarantees</i></a>, the implementation does not ensure that the thread will eventually
make progress.</p></div><div class='para' id='intro.progress-12'><div class='marginalizedparent'><a class='marginalized' href='#intro.progress-12'>12</a></div><p >[&nbsp;<i>Note:</i><span class='space'></span>
Threads of execution providing weakly parallel forward progress guarantees cannot
be expected to make progress regardless of whether other threads make progress or
not; however, blocking with forward progress guarantee delegation, as defined below,
can be used to ensure that such threads of execution make progress eventually.
<i>&nbsp;—&nbsp;end note</i>&nbsp;]</p></div><div class='para' id='intro.progress-13'><div class='marginalizedparent'><a class='marginalized' href='#intro.progress-13'>13</a></div><p >Concurrent forward progress guarantees are stronger than parallel forward progress
guarantees, which in turn are stronger than weakly parallel forward progress
guarantees.
[&nbsp;<i>Note:</i><span class='space'></span>
For example, some kinds of synchronization between threads of execution may only
make progress if the respective threads of execution provide parallel forward progress
guarantees, but will fail to make progress under weakly parallel guarantees.
<i>&nbsp;—&nbsp;end note</i>&nbsp;]</p></div><div class='para' id='intro.progress-14'><div class='marginalizedparent'><a class='marginalized' href='#intro.progress-14'>14</a></div><p ><span class='indexparent'><a class='index' id='forward_progress_guarantees,delegation_of'></a></span>When a thread of execution <i>P</i> is specified to <a id='block_with_forward_progress_guarantee_delegation'><i>block with forward
progress guarantee delegation</i></a> on the completion of a set <i>S</i> of threads
of execution, then throughout the whole time of <i>P</i> being blocked on
<i>S</i>, the implementation shall ensure that the forward progress guarantees
provided by at least one thread of execution in <i>S</i> is at least as strong
as <i>P</i>'s forward progress guarantees.
[&nbsp;<i>Note:</i><span class='space'></span>
It is unspecified which thread or threads of execution in <i>S</i> are chosen
and for which number of execution steps. The strengthening is not permanent and
not necessarily in place for the rest of the lifetime of the affected thread of
execution. As long as <i>P</i> is blocked, the implementation has to eventually
select and potentially strengthen a thread of execution in <i>S</i>.
<i>&nbsp;—&nbsp;end note</i>&nbsp;]
Once a thread of execution in <i>S</i> terminates, it is removed from <i>S</i>.
Once <i>S</i> is empty, <i>P</i> is unblocked.</p></div><div class='para' id='intro.progress-15'><div class='marginalizedparent'><a class='marginalized' href='#intro.progress-15'>15</a></div><p >[&nbsp;<i>Note:</i><span class='space'></span>
A thread of execution <i>B</i> thus can temporarily provide an effectively
stronger forward progress guarantee for a certain amount of time, due to a
second thread of execution <i>A</i> being blocked on it with forward
progress guarantee delegation. In turn, if <i>B</i> then blocks with
forward progress guarantee delegation on <i>C</i>, this may also temporarily
provide a stronger forward progress guarantee to <i>C</i>.
<i>&nbsp;—&nbsp;end note</i>&nbsp;]</p></div><div class='para' id='intro.progress-16'><div class='marginalizedparent'><a class='marginalized' href='#intro.progress-16'>16</a></div><p >[&nbsp;<i>Note:</i><span class='space'></span>
If all threads of execution in <i>S</i> finish executing (e.g., they terminate
and do not use blocking synchronization incorrectly), then <i>P</i>'s execution
of the operation that blocks with forward progress guarantee delegation will not
result in <i>P</i>'s progress guarantee being effectively weakened.
<i>&nbsp;—&nbsp;end note</i>&nbsp;]</p></div><div class='para' id='intro.progress-17'><div class='marginalizedparent'><a class='marginalized' href='#intro.progress-17'>17</a></div><p >[&nbsp;<i>Note:</i><span class='space'></span>
This does not remove any constraints regarding blocking synchronization for
threads of execution providing parallel or weakly parallel forward progress
guarantees because the implementation is not required to strengthen a particular
thread of execution whose too-weak progress guarantee is preventing overall progress.
<i>&nbsp;—&nbsp;end note</i>&nbsp;]</p></div><div class='para' id='intro.progress-18'><div class='marginalizedparent'><a class='marginalized' href='#intro.progress-18'>18</a></div><p >An implementation should ensure that the last value (in modification order)
assigned by an atomic or synchronization operation will become visible to all
other threads in a finite period of time.<span class='indexparent'><a class='index' id='operation,atomic'></a></span><span class='indexparent'><a class='index' id='threads,multiple'></a></span></p></div></div></div></div></body></html>